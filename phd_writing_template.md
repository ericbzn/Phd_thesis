# PHD WRITING TEMPLATE

------

## *Thesis template Draw N°1*

### <u>**Title:** Vision Methods for Navigation of Unmanned Aerial Vehicles (UAVs)</u>

### **Aims and objectives** (If someone asked you what is my thesis about, this is what I said)

*<u>Aim:</u>* Propose computer vision algorithms to aid autonomous drone navigation.

*<u>Scopes:</u>*  

- Monochrome and/or RGB cameras as sensors for data acquisition

- Use of classic methods of image analysis for segmentation/ detection of objects

*<u>Gap:</u>* 

- Insufficiency of computer vision algorithms robust enough to the natural disturbances generated in missions with drones.

*<u>Main argument:</u>*

There are hundreds of highly performing algorithms for image segmentation and object detection based on neural networks and artificial intelligence, however, these algorithms are in trouble when it comes to image analysis of complex scenarios or applications where there are no a database rich enough to do the learning process.

*<u>Contribution:</u>*

A new vision framework able to provide aid in the automated decision chain of UAVs in complex scenarios.

------

## *Thesis template Draw N°2*

### <u>**Title:** Traditional Computer Vision Methods for Unmanned Aerial Vehicles (UAVs) Applications</u>

### **Aims and objectives** (If someone asked you what is my thesis about, this is what I said)

*<u>Aim:</u>* 

Propose computer vision algorithms for object detection/segmentation using classic machine learning approaches and low-level features for the image analysis.

*<u>Scopes:</u>*  

- Vision-based methods to aid autonomous drone navigation.

- Monochrome and/or RGB cameras as sensors for data acquisition.

*<u>Gaps:</u>* 

- Abandonment of classical methods for image analysis.
- Lack of unsupervised methods in image analysis for applications such as the drone navigation.
- Insufficiency of computer vision algorithms robust enough to the natural disturbances generated in missions with drones.

*<u>Main argument:</u>*

There are hundreds of highly performing algorithms for image segmentation and object detection based on neural networks and artificial intelligence, however, these algorithms are in trouble when it comes to image analysis of complex scenarios or applications where there are no a database rich enough to do the learning process.

*<u>Contribution:</u>*

A new vision framework able to perform the detection/segmentation of objects in an unsupervised way based on low-level image features and classic image analysis theory. This framework is tested on applications/situations developed in complex scenarios related with providing aid in the automated decision chain of UAV’s navigation.

------

### **1. Acknowledges**

------

### **2. Abstract**

------

### **3. Introduction**

*<u>What is the thesis problem statement?</u>*

Problems linked to computer vision applications for air vehicles are generated by the nature of the object detection task for autonomous navigation. Such missions are generally carried out in complex scenes that change as the vehicle moves through space. For example, a drone that delivers packages can start its route in a commercial area, passing through rural areas until the order is delivered within an urban area. In this case we find situations where visual information and objects suffer deformations due to changes in height and direction of the vehicle. In addition, the images captured by the drone can present strong changes in lighting and the presence of shadows that disturb the perception of a scene.

*<u>What do I (not) hope to achieve?</u>*

1. Generate a general image analysis framework for applications related with the autonomous navigation of aerial vehicles.

2. Test the framework for object detection in complex situations/scenarios such as those that may occur in applications such as autonomous navigation of air vehicles.

3. To compare qualitatively and quantitatively the detection / segmentation results of image objects with the most widely used algorithms in the literature based on deep learning techniques and with the most outstanding state-of-art methods based on traditional computer vision techniques.

*<u>What are the research questions and hypotheses?</u>*

1. Traditional computer vision methods are (still) a reliable option to develop the object detection and recognition.

2. New deep learning techniques have need of traditional computer vision methods for overcome the lack of labeled data problem.

*<u>What is my contribution to the field?</u>*

1. A new framework based on low-level image primitives that allows detection of objects in a totally unsupervised way.

2. A comparative study between the widely used image detection / segmentation techniques using deep learning architectures and traditional computer vision techniques.

3. In general terms, this thesis contributes to the debate between deep learning computer vision techniques and traditional computer vision techniques in the sense that it explores and attempts to solve highly complex problems without the need for an annotated database.

*<u>How is my thesis laid out?</u>*

Throughout this research work I used different low-level image primitives as a source of information to develop a framework for object detection and recognition. The development process of this framework was evolutionary, where each time it was added a new primitive to enrich the representation of the image. Thus, my thesis laid out follows this evolutionary process of the research work: The first part of the thesis is devoted to the study of existing contours / edges in an image. I used this information for the detection of landing paths related with the autonomous landing drone task. The second part of this document is dedicated to the study of color information in an image. This part serves as an introduction to the third part of the thesis, dedicated to the study of textures generated by the lighting changes. These two parts engage in an image search system from a query image that shows the importance of color spaces and texture in image analysis. Part number four brings together the theory used in the preceding parts to create a framework that analyzes the colors of the textures as well as the textures generated by lighting changes. In this part we show the high-level primitives that can be obtained from the proposed image representation and present a comparison between various clustering methods obtain a totally unsupervised image segmentation.

**Introduction writing**

<u>What is Computer Vision?</u>

*Situation:* Computer Vision (CV) is about making machines capable of seeing and perceiving the world as humans do.

*Problem/Question:* Replicating the behavior of human vision on machines is a difficult task. The tasks that human vision performs  quite effortlessly and effectively, for a machine could represent a complex task.

*Solution:* There have been a large number of studies to date which have tried to understad what is the nature of computation involved in visual tasks. Researchers from various fields of study such as biology, neuroscience and computer science have attempted to answer the question of how we might build the machines to be able to see and understand the world as we do.

<u>Timelines and Milestones</u>

*Situation:* Computer vison is a rapidly evolving field. 

*Problem/Question:* What are the milestone works in CV field? To understand where we are today, it is important to know the history and the key milestones that has made this field grow.

*Solution/Answer:* La tres líneas de investigación con las cuales nació la visión por computadora en los años 1950 son la replicación del ojo, la replicación de la corteza visual y la replicación del resto del cerebro. El trabajo conjunto entre psicólogos y científicos computacionales propicio el desarrollo de la máquina Perceptron en el año de 1957, mismo año que marco el nacimiento del píxel. 

The three lines of research with which computer vision was born in the 1950s are replication of the eye, replication of the visual cortex, and replication of the rest of the brain. The joint work between psychologists and computer scientists led to the development of the Perceptron machine in 1957, the same year that marked the birth of the pixel.

Para la década de los años 1960, las problemáticas de la visión por computadora estaban ligadas a la representación de objetos sólidos en 3D mediante figuras más simples en 2D. Tales problemáticas junto con otras ideas como la de conectar una cámara a un ordenador para describir lo que veía, motivaron la creación del Laboratorio de Inteligencia Artificial del MIT; después de más de 50 años, esta es una idea que continúa trabajándose. 

By the 1960s, the problems of computer vision were linked to the representation of solid objects in 3D using simpler 2D figures. Such problems, along with other ideas such as connecting a camera to a computer to describe what he saw, motivated the creation of the MIT Artificial Intelligence Laboratory; After more than 50 years, this is an idea that continues to work.

Muchos de los algoritmos de visión que conocemos el día de hoy, tales como la extracción de bordes de imágenes, la labialización de líneas, modelado y representación de objetos como interconexiones de estructuras más pequeñas, flujo óptico y la estimación de movimiento, fueron creados en la década de los años 1970. Todas ellas impulsadas por las primeras aplicaciones comerciales de la visión por computadora como el reconocimiento de caracteres óptico (OCR) y por la aparición de la primera cámara comercial. 

Many of the vision algorithms that we know today, such as image edge extraction, line labialization, modeling, and object representation such as interconnections of smaller structures, optical flow, and motion estimation, were created in the 1970s. All of them driven by the first commercial applications of computer vision such as optical character recognition (OCR) and by the appearance of the first commercial camera.

La década de los 80 la podemos caracterizar por la aparición de estudios basados en análisis matemáticos más rigurosos y en aspectos cuantitativos. Muchos algoritmos de análisis de imágenes no lineares como la morfología matemática fueron generalizados para funciones en escalas de grises e imágenes. 

The 80's can be characterized by the appearance of studies based on more rigorous mathematical analysis and on quantitative aspects. Many non-linear image analysis algorithms such as mathematical morphology were generalized for grayscale and image functions.

La investigación de reconstrucciones 3D a partir de proyecciones o escenas a partir de múltiples imágenes así como la calibración de la cámara llegaron en la década de los 1990. Junto a esto, hubo avances en el campo de imagen estéreo y técnicas de multi-vista estéreo. Además, se utilizaron variaciones de algoritmos de corte de gráficas para la segmentación de imágenes habilitando así la interpretación de alto nivel de las regiones coherentes de una imagen. 

Investigation of 3D reconstructions from projections or scenes from multiple images as well as camera calibration came in the 1990s. Along with this, there were advances in the field of stereo imaging and stereo multi-view techniques. . In addition, variations of graph cutting algorithms were used for image segmentation thus enabling high-level interpretation of the coherent regions of an image.

Para los años 2000 existía una basta gama de aplicaciones y campos relacionados con la visión por computadora. Algunos de los temas más relevantes de ese tiempo son la detección de rostros, traídos a la fama por Viola y Jones, la Transformada de Features Invariantes de la Escala (SIFT) desarrollado por Lowe así como la aparición de las Redes Neuronales, que dieron paso a los métodos de aprendizaje. Esta década marco un gran avance para la visión por computadora gracias gran cantidad de set de datos anotados que había accesible en internet. Con ellos, era posible proponer retos cada vez más complejos,  lo que permitió comparar y ordenar cuantitativamente las técnicas de visión por computadora. 

By the 2000s, there was a vast range of applications and fields related to computer vision. Some of the most relevant topics from that time are face detection, brought to fame by Viola and Jones, Lowe's Invariant Scale Features Transform (SIFT) developed as well as the appearance of Neural Networks, which gave way to learning methods. This decade marked a breakthrough for computer vision thanks to the large number of annotated data sets that were accessible on the internet. With them, it was possible to propose increasingly complex challenges, which allowed comparing and quantifying computer vision techniques.

En la última década las técnicas basadas en métodos de aprendizaje han tomado popularidad. Un hito de esta época es la gran base de datos visual ImageNet, creada en el 2009 para la investigación de software de reconocimiento de objetos visuales. Desde el 2010, el proyecto organiza una competencia anual de software, la ImageNet Large Scale Visual Recognition Challenge (ILSVRC), donde los software compiten para clasificar correctamente los objetos y escenas de la base de datos. Hasta el 2012 ningún programa había sido tan relevante como lo fue AlexNet, una red neuronal convolutiva profunda la cual supero los trabajos del estado del arte de ese momento. Sin duda alguna los resultados de esta competencia marcaron la historia de la visión por computadora. En los últimos años el estudio de las CNNs ha sido exponencial, dando paso a  novedosos sistemas como las GANs las cuales buscan hacer más robustas las CNNs. 

Techniques based on learning methods have become popular in the last decade. A milestone of this time is the large ImageNet visual database, created in 2009 for research on visual object recognition software. Since 2010, the project has organized an annual software competition, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), where software competes to correctly classify objects and scenes in the database. Until 2012, no program had been as relevant as AlexNet, a deep convolutional neural network which surpassed the state of the art works of that time. The results of this competition undoubtedly marked the history of computer vision. In recent years, the study of CNNs has been exponential, giving way to novel systems such as GANs, which seek to make CNNs more robust.

Las redes neuronales convolutivas no solo se volvieron la elección de muchos investigadores para llevar a cabo aplicaciones de visión por computadora, grandes empresas como Google, Amazon, Facebook y Apple (GAFA) han impulsado la investigación y el desarrollo en este campo. Un ejemplo remarcable es el algoritmo DeepFace para el reconocimiento facial. El algoritmo propuesto por los investigadores de Facebook es capaz de identificar rostros de manera correcta 97% del tiempo, siendo este resultado comparable con la detección que un humano puede hacer.

Convolutionary neural networks not only became the choice of many researchers to carry out computer vision applications, large companies such as Google, Amazon, Facebook and Apple (GAFA) have promoted research and development in this field. A remarkable example is the DeepFace algorithm for facial recognition. The algorithm proposed by the Facebook researchers is capable of correctly identifying faces 97% of the time, this result being comparable to the detection that a human can do.

<u>Applications and Taks</u>

*Situation:* El avance de las técnicas de Visión por Computadora ha favorecido su utilización en un rango amplio de aplicaciones. El desarrollo ha sido sobresaliente en áreas de aplicación ya tradicionales como la multimedia, robótica o la medicina. Sin embargo, nuevas áreas de aplicación siguen surgiendo como la realidad aumentada, la conducción automática, el internet de las cosas y la industria 4.0, la interacción hombre-computadora y la visión para ciegos. Algunas áreas menos tradicionales donde la Visión por Computadora esta cada vez más presente son la astronomía, la nanotecnología, las nuevas técnicas de imágenes del cerebro, entre otra más.

The advancement of Computer Vision techniques has favored its use in a wide range of applications. The development has been outstanding in already traditional application areas such as multimedia, robotics or medicine. However, new areas of application continue to emerge such as augmented reality, automated driving, the Internet of Things and Industry 4.0, human-computer interaction and vision for the blind. Some less traditional areas where Computer Vision is increasingly present are astronomy, nanotechnology, new brain imaging techniques, among others.

Si bien la visión por computadora ha sobrepasado las capacidades de la visión humana, las computadoras no han remplazado por completo al personal humano. Por ejemplo,  en el caso de las tareas de los sistemas de visión industrial,  digamos inspeccionar botellas o tarjetas de circuitos en una línea de producción, la visión por computadora supera a los humanos. Sin embargo, en áreas como la imagen medica, los sistemas de visión por computadora solo se encargan de complementar ciertos diagnósticos de rutina que requieren mucho tiempo y experiencia de los médicos humanos. En gran medida esto está relacionado con la complejidad de la tarea y de las condiciones donde se lleva a cabo la aplicación.  En el caso de los sistemas de visión para máquinas, generalmente las condiciones de trabajo son controladas, mientras que en áreas coma la medicina, cada imagen de paciente es distinta a pesar de que el sistema de adquisición sea el mismo. 

While computer vision has outstripped the capabilities of human vision, computers have not completely replaced human personnel. For example, in the case of industrial vision systems tasks, say inspecting bottles or circuit boards on a production line, computer vision surpasses humans. However, in areas such as medical imaging, computer vision systems are only responsible for supplementing certain routine diagnoses that require a lot of time and experience from human doctors. This is largely related to the complexity of the task and the conditions under which the application is carried out. In the case of machine vision systems, working conditions are generally controlled, while in areas such as medicine, each patient image is different despite the fact that the acquisition system is the same.

Independientemente de la aplicación, los sistemas de visión por computador deben llevar a cabo una serie de tareas para lograr su fin. De manera general, estas tareas incluyen los métodos para la adquisición, procesamiento, análisis y comprensión de imágenes digitales y, la extracción de datos del mundo real para producir información simbólica, por ejemplo, en forma de decisiones.  Dependiendo del contexto, entender las imágenes puede significar la transformación las imágenes visuales (la entrada del sensor) en descripciones del mundo que pueden interactuar con otros procesos y provocar la acción adecuada. Esta compresión puede verse como el desmenuzado de la información simbólica de la imagen utilizando modelos geométricos, físicos, estadísticos o de la teoría del aprendizaje.

Regardless of the application, computer vision systems must perform a number of tasks to achieve their end. Generally, these tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extracting real-world data to produce symbolic information, for example, in the form of decisions. Depending on the context, understanding images can mean transforming visual images (the sensor input) into descriptions of the world that can interact with other processes and provoke appropriate action. This compression can be seen as the crumbling of the symbolic information in the image using geometric, physical, statistical or theory of learning models.

De manera más particular, las tareas de la visión por computadora pueden agruparse en cuatro más o menos bien definidos problemas de procesamiento: El reconocimiento, problema clásico de la visión por computadora el cual se encarga de determinar si una imagen contiene algún objeto, característica o actividad. Algunas variantes de este problema son la clasificación, la identificación y la detección de objetos de las cuales se desprenden muchas tareas especializadas, por ejemplo, la búsqueda de imágenes basadas en el contenido, la estimación de pose, el reconocimiento óptico de caracteres, lectura de códigos 2D, el reconocimiento facial, el reconocimiento de formas, entre otros.

More particularly, the tasks of computer vision can be grouped into four more or less well-defined processing problems: Recognition, a classic problem of computer vision which is responsible for determining whether an image contains any object, characteristic or exercise. Some variants of this problem are the classification, identification and detection of objects from which many specialized tasks emerge, for example, content-based image search, pose estimation, optical character recognition, reading of 2D codes, facial recognition, shape recognition, among others.

El análisis de movimiento, en el cual una secuencia de imágenes es procesada para producir una estimación de la velocidad de uno o varios puntos de interés dentro de una imagen o una escena 3D. Algunos ejemplos de esta tarea son el egomotion, el traqueo de objetos y el flujo óptico.

Motion analysis, in which a sequence of images is processed to produce an estimate of the speed of one or more points of interest within a 3D image or scene. Some examples of this task are egomotion, object tracking, and optical flow.

La reconstrucción de escenas, que es tarea relacionada con el cómputo de un modelo 3D a partir de una o varias imágenes de una escena.

The reconstruction of scenes, which is a task related to the computation of a 3D model from one or more images of a scene.

La restauración de imágenes, cuyo objetivo es el de remover aquellas imperfecciones de una imagen generado por perturbaciones tales como el ruido del sensor o el desenfoque por movimiento. Generalmente esta tarea es llevada cabo en el preprocesamiento de la imagen antes de pasarla a un algoritmo de visón más complejo. Un ejemplo en el cual se aplica esta tarea es el inpainting

 The restoration of images, whose objective is to remove those imperfections of an image generated by disturbances such as sensor noise or motion blur. Generally this task is carried out in the pre-processing of the image before passing it to a more complex mink algorithm. An example in which this task is applied is inpainting

Hoy en día es un momento emocionante para trabajar en la visión por computadora. El amplio acceso gratuito a datos en línea,  el avance tecnológico de las computadoras y el acceso a ellas para el tratamiento de estos datos han favorecido el desarrollo de esta área de estudio. No solo desde un punto de vista científico sino también desde un punto de vista comercial y social. La visión por computadora se ha convertido en una tecnología integral en nuestra vida diaria.

Today is an exciting time to work on computer vision. The wide free access to online data, the technological advancement of computers and access to them for the treatment of these data have favored the development of this area of study. Not only from a scientific point of view but also from a commercial and social point of view. Computer vision has become an integral technology in our daily life.

