# PHD WRITING TEMPLATE

------

## *Thesis template Draw N°1*

### <u>**Title:** Vision Methods for Navigation of Unmanned Aerial Vehicles (UAVs)</u>

### **Aims and objectives** (If someone asked you what is my thesis about, this is what I said)

*<u>Aim:</u>* Propose computer vision algorithms to aid autonomous drone navigation.

*<u>Scopes:</u>*  

- Monochrome and/or RGB cameras as sensors for data acquisition

- Use of classic methods of image analysis for segmentation/ detection of objects

*<u>Gap:</u>* 

- Insufficiency of computer vision algorithms robust enough to the natural disturbances generated in missions with drones.

*<u>Main argument:</u>*

There are hundreds of highly performing algorithms for image segmentation and object detection based on neural networks and artificial intelligence, however, these algorithms are in trouble when it comes to image analysis of complex scenarios or applications where there are no a database rich enough to do the learning process.

*<u>Contribution:</u>*

A new vision framework able to provide aid in the automated decision chain of UAVs in complex scenarios.

------

## *Thesis template Draw N°2*

### <u>**Title:** Traditional Computer Vision Methods for Unmanned Aerial Vehicles (UAVs) Applications</u>

### **Aims and objectives** (If someone asked you what is my thesis about, this is what I said)

*<u>Aim:</u>* 

Propose computer vision algorithms for object detection/segmentation using classic machine learning approaches and low-level features for the image analysis.

*<u>Scopes:</u>*  

- Vision-based methods to aid autonomous drone navigation.

- Monochrome and/or RGB cameras as sensors for data acquisition.

*<u>Gaps:</u>* 

- Abandonment of classical methods for image analysis.
- Lack of unsupervised methods in image analysis for applications such as the drone navigation.
- Insufficiency of computer vision algorithms robust enough to the natural disturbances generated in missions with drones.

*<u>Main argument:</u>*

There are hundreds of highly performing algorithms for image segmentation and object detection based on neural networks and artificial intelligence, however, these algorithms are in trouble when it comes to image analysis of complex scenarios or applications where there are no a database rich enough to do the learning process.

*<u>Contribution:</u>*

A new vision framework able to perform the detection/segmentation of objects in an unsupervised way based on low-level image features and classic image analysis theory. This framework is tested on applications/situations developed in complex scenarios related with providing aid in the automated decision chain of UAV’s navigation.

------

### **1. Acknowledges**

------

### **2. Abstract**

------

### **3. Introduction**

*<u>What is the thesis problem statement?</u>*

Problems linked to computer vision applications for air vehicles are generated by the nature of the object detection task for autonomous navigation. Such missions are generally carried out in complex scenes that change as the vehicle moves through space. For example, a drone that delivers packages can start its route in a commercial area, passing through rural areas until the order is delivered within an urban area. In this case we find situations where visual information and objects suffer deformations due to changes in height and direction of the vehicle. In addition, the images captured by the drone can present strong changes in lighting and the presence of shadows that disturb the perception of a scene.

*<u>What do I (not) hope to achieve?</u>*

1. Generate a general image analysis framework for applications related with the autonomous navigation of aerial vehicles.

2. Test the framework for object detection in complex situations/scenarios such as those that may occur in applications such as autonomous navigation of air vehicles.

3. To compare qualitatively and quantitatively the detection / segmentation results of image objects with the most widely used algorithms in the literature based on deep learning techniques and with the most outstanding state-of-art methods based on traditional computer vision techniques.

*<u>What are the research questions and hypotheses?</u>*

1. Traditional computer vision methods are (still) a reliable option to develop the object detection and recognition.

2. New deep learning techniques have need of traditional computer vision methods for overcome the lack of labeled data problem.

*<u>What is my contribution to the field?</u>*

1. A new framework based on low-level image primitives that allows detection of objects in a totally unsupervised way.

2. A comparative study between the widely used image detection / segmentation techniques using deep learning architectures and traditional computer vision techniques.

3. In general terms, this thesis contributes to the debate between deep learning computer vision techniques and traditional computer vision techniques in the sense that it explores and attempts to solve highly complex problems without the need for an annotated database.

*<u>How is my thesis laid out?</u>*

Throughout this research work I used different low-level image primitives as a source of information to develop a framework for object detection and recognition. The development process of this framework was evolutionary, where each time it was added a new primitive to enrich the representation of the image. Thus, my thesis laid out follows this evolutionary process of the research work: The first part of the thesis is devoted to the study of existing contours / edges in an image. I used this information for the detection of landing paths related with the autonomous landing drone task. The second part of this document is dedicated to the study of color information in an image. This part serves as an introduction to the third part of the thesis, dedicated to the study of textures generated by the lighting changes. These two parts engage in an image search system from a query image that shows the importance of color spaces and texture in image analysis. Part number four brings together the theory used in the preceding parts to create a framework that analyzes the colors of the textures as well as the textures generated by lighting changes. In this part we show the high-level primitives that can be obtained from the proposed image representation and present a comparison between various clustering methods obtain a totally unsupervised image segmentation.

**Introduction writing**

<u>What is Computer Vision?</u>

*Situation:* Computer Vision (CV) is about making machines capable of seeing and perceiving the world as humans do.

*Problem/Question:* Replicating the behavior of human vision on machines is a difficult task. The tasks that human vision performs  quite effortlessly and effectively, for a machine could represent a complex task.

*Solution:* There have been a large number of studies to date which have tried to understad what is the nature of computation involved in visual tasks. Researchers from various fields of study such as biology, neuroscience and computer science have attempted to answer the question of how we might build the machines to be able to see and understand the world as we do.

<u>Timelines and Milestones</u>

*Situation:* Computer vison is a rapidly evolving field. 

*Problem/Question:* What are the milestone works in CV field? To understand where we are today, it is important to know the history and the key milestones that has made this field grow.

*Solution/Answer:* La tres líneas de investigación con las cuales nació la visión por computadora en los años 1950 son la replicación del ojo, la replicación de la corteza visual y la replicación del resto del cerebro. El trabajo conjunto entre psicólogos y científicos computacionales propicio el desarrollo de la máquina Perceptron en el año de 1957, mismo año que marco el nacimiento del píxel. 

The three lines of research with which computer vision was born in the 1950s are replication of the eye, replication of the visual cortex, and replication of the rest of the brain. The joint work between psychologists and computer scientists led to the development of the Perceptron machine in 1957, the same year that marked the birth of the pixel.

Para la década de los años 1960, las problemáticas de la visión por computadora estaban ligadas a la representación de objetos sólidos en 3D mediante figuras más simples en 2D. Tales problemáticas junto con otras ideas como la de conectar una cámara a un ordenador para describir lo que veía, motivaron la creación del Laboratorio de Inteligencia Artificial del MIT; después de más de 50 años, esta es una idea que continúa trabajándose. 

By the 1960s, the problems of computer vision were linked to the representation of solid objects in 3D using simpler 2D figures. Such problems, along with other ideas such as connecting a camera to a computer to describe what he saw, motivated the creation of the MIT Artificial Intelligence Laboratory; After more than 50 years, this is an idea that continues to work.

Muchos de los algoritmos de visión que conocemos el día de hoy, tales como la extracción de bordes de imágenes, la labialización de líneas, modelado y representación de objetos como interconexiones de estructuras más pequeñas, flujo óptico y la estimación de movimiento, fueron creados en la década de los años 1970. Todas ellas impulsadas por las primeras aplicaciones comerciales de la visión por computadora como el reconocimiento de caracteres óptico (OCR) y por la aparición de la primera cámara comercial. 

Many of the vision algorithms that we know today, such as image edge extraction, line labialization, modeling, and object representation such as interconnections of smaller structures, optical flow, and motion estimation, were created in the 1970s. All of them driven by the first commercial applications of computer vision such as optical character recognition (OCR) and by the appearance of the first commercial camera.

La década de los 80 la podemos caracterizar por la aparición de estudios basados en análisis matemáticos más rigurosos y en aspectos cuantitativos. Muchos algoritmos de análisis de imágenes no lineares como la morfología matemática fueron generalizados para funciones en escalas de grises e imágenes. 

The 80's can be characterized by the appearance of studies based on more rigorous mathematical analysis and on quantitative aspects. Many non-linear image analysis algorithms such as mathematical morphology were generalized for grayscale and image functions.

La investigación de reconstrucciones 3D a partir de proyecciones o escenas a partir de múltiples imágenes así como la calibración de la cámara llegaron en la década de los 1990. Junto a esto, hubo avances en el campo de imagen estéreo y técnicas de multi-vista estéreo. Además, se utilizaron variaciones de algoritmos de corte de gráficas para la segmentación de imágenes habilitando así la interpretación de alto nivel de las regiones coherentes de una imagen. 

Investigation of 3D reconstructions from projections or scenes from multiple images as well as camera calibration came in the 1990s. Along with this, there were advances in the field of stereo imaging and stereo multi-view techniques. . In addition, variations of graph cutting algorithms were used for image segmentation thus enabling high-level interpretation of the coherent regions of an image.

Para los años 2000 existía una basta gama de aplicaciones y campos relacionados con la visión por computadora. Algunos de los temas más relevantes de ese tiempo son la detección de rostros, traídos a la fama por Viola y Jones, la Transformada de Features Invariantes de la Escala (SIFT) desarrollado por Lowe así como la aparición de las Redes Neuronales, que dieron paso a los métodos de aprendizaje. Esta década marco un gran avance para la visión por computadora gracias gran cantidad de set de datos anotados que había accesible en internet. Con ellos, era posible proponer retos cada vez más complejos,  lo que permitió comparar y ordenar cuantitativamente las técnicas de visión por computadora. 

By the 2000s, there was a vast range of applications and fields related to computer vision. Some of the most relevant topics from that time are face detection, brought to fame by Viola and Jones, Lowe's Invariant Scale Features Transform (SIFT) developed as well as the appearance of Neural Networks, which gave way to learning methods. This decade marked a breakthrough for computer vision thanks to the large number of annotated data sets that were accessible on the internet. With them, it was possible to propose increasingly complex challenges, which allowed comparing and quantifying computer vision techniques.

En la última década las técnicas basadas en métodos de aprendizaje han tomado popularidad. Un hito de esta época es la gran base de datos visual ImageNet, creada en el 2009 para la investigación de software de reconocimiento de objetos visuales. Desde el 2010, el proyecto organiza una competencia anual de software, la ImageNet Large Scale Visual Recognition Challenge (ILSVRC), donde los software compiten para clasificar correctamente los objetos y escenas de la base de datos. Hasta el 2012 ningún programa había sido tan relevante como lo fue AlexNet, una red neuronal convolutiva profunda la cual supero los trabajos del estado del arte de ese momento. Sin duda alguna los resultados de esta competencia marcaron la historia de la visión por computadora. En los últimos años el estudio de las CNNs ha sido exponencial, dando paso a  novedosos sistemas como las GANs las cuales buscan hacer más robustas las CNNs. 

Techniques based on learning methods have become popular in the last decade. A milestone of this time is the large ImageNet visual database, created in 2009 for research on visual object recognition software. Since 2010, the project has organized an annual software competition, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), where software competes to correctly classify objects and scenes in the database. Until 2012, no program had been as relevant as AlexNet, a deep convolutional neural network which surpassed the state of the art works of that time. The results of this competition undoubtedly marked the history of computer vision. In recent years, the study of CNNs has been exponential, giving way to novel systems such as GANs, which seek to make CNNs more robust.

Las redes neuronales convolutivas no solo se volvieron la elección de muchos investigadores para llevar a cabo aplicaciones de visión por computadora, grandes empresas como Google, Amazon, Facebook y Apple (GAFA) han impulsado la investigación y el desarrollo en este campo. Un ejemplo remarcable es el algoritmo DeepFace para el reconocimiento facial. El algoritmo propuesto por los investigadores de Facebook es capaz de identificar rostros de manera correcta 97% del tiempo, siendo este resultado comparable con la detección que un humano puede hacer.

Convolutionary neural networks not only became the choice of many researchers to carry out computer vision applications, large companies such as Google, Amazon, Facebook and Apple (GAFA) have promoted research and development in this field. A remarkable example is the DeepFace algorithm for facial recognition. The algorithm proposed by the Facebook researchers is capable of correctly identifying faces 97% of the time, this result being comparable to the detection that a human can do.

<u>Applications and Taks</u>

*Situation:* El avance de las tecnicas de Vision por Computadora ha favorecido su utilizacion en un rango amplio de aplicaciones. El desarrollo ha sido sobresaliente en areas de aplicacion ya tradicionales como la multimedia, robotica o la medicina. Sin embargo, nuevas areas de aplicacion siguen surgiendo como la realidad aumentada, la conduccion automatica, el internet de las cosas y la industria 4.0, la interaccion hombre-computadora y la vision para ciegos. Algunas areas menos tradicionales donde la Vision por Computadora esta cada vez ma presente son la astronomia, la nanotecnología, las nuevas tecnicas de imagenes del cerebro, entre otra mas.

Si bien la vision por computadora ha sobre pasado las capacidades de la vision humana, las computadoras no han remplazado por completo al personal humano. Por ejemplo,  en el caso de las tareas de los sistemas de vision industrial,  digamos inspeccionar botellas o tarjetas de circuitos en una linea de produccion, la vision por computadora supera a los humanos. Sin embargo, en areas como la imagen medica, los sistemas de vision por computadora solo se encargan de complementar ciertos diagnosticos de rutina que requieren mucho tiempo y experiencia de los medicos humanos. En gran medida esto esta relacionado con la complejidad de la tarea y de las condiciones donde se lleva a cabo la aplicacion.  En el caso de los sistemas de vision para maquinas, generalmente las condiciones de trabajo son controladas, mientras que en areas coma la medicina, cada imagen de paciente es distinta a pesar de que el sistema de adquicicion sea el mismo. 

Independientemente de la aplicacion, los sistemas de vision por computador deben llevar a cabo una serie de tareas para lograr su fin. De manera general, estas tareas incluyen los metodos para la adquisicion, procesamiento, analisis y comprehension de imagenes digitales y, la extraccion de datos del mundo real para producir informacion simbolica, por ejemplo, en forma de decisiones.  Dependiendo del contexto, entender las imagenes puede signficar la transformarción la imagenes visuales (la entrada del sensor) en descripciones del mundo que pueden intereactuar con otros procesos y provocar la accion adecuada. Esta compresion puede verse como el desmenuzado de la informacion simbolica de la imagen utilizando modelos geometricos, fisicos, estadisticos o de la teoría del aprendizaje.

De manera mas particular, las tareas de la vision por computadora pueden agruparse en cuatro mas o menos bien difinidos problemas de procesamiento: El reconociemiento, problema clásico de la vision por computadora el cual se encarga de determinar si una imagen contine algún objeto, carateristica o acitividad. Algunas variantes de este problema son la clasificacion, la identificacion y la deteccion de objetos de las cuales se desprenden muchas tareas especializadas, por ejemplo, la busqueda de images basadas en el contenido, la estimacion de pose, el reconocimiento optico de carateres, lectura de codigos 2D, el reconicimiento facial, el reconocimiento de formas, entre otros.

El analisis de movimieto, en el cual una secuancia de imagenes es procesada para producir una estimacion de la velocidad de uno o varios puntos de interes dentro de una imagen o una escena 3D. Algunos ejemplos de esta tarea son el egomotion, el traqueo de objetos y el flujo óptico.

La reconstruccion de escenas, tarea realacionada con el computo de un modelo 3D a partir de una o varias imagenes de una escena.

La restauracion de images, cuyo objetivo es el de remover aquellas imperfecciones de una imagen generado por perturbaciones tales como el ruido del sensor o el desenforque por movimiento. Generalmente esta tarea es llevada cabo en el pre procesamiento de la images antes de pasarla a un algoritmo de vison mas complejo. Un ejemplo en el cual se aplica esta tarea es el inpainting



 

*Problem/Question:* Tales aplicaciones abarcan el campo de la medicina, donde los algoritmos ayudan al diagnostico de enfermedades mediante la identificacion patrones en imagenes medicales. En el sector industrial, el control de las condiciones de trabajo favorece la implentacion de algoritmos deteccion o supervision que superan las capacidades humanas.   
*Solution/Answer::*

