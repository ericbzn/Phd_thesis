% created on 12/05/2020
% @author : ebazan

\chapter{Color image texture analysis based on Gabor features}\label{ch:complex_spectral_image_decomposition}
\section*{Résumé}
\noindent Dans ce chapitre, nous présentons la décomposition spectrale d'une image couleur avec l'aide du filtre de Gabor. Nous utilisons la théorie sur les fonctions de Gabor développée dans le Chapitre \ref{ch:image_spectral_decomposition} pour extraire les caractéristiques de texture locale d'une image en couleurs. La stratégie principale consiste à transformer l'image d'entrée d'un espace couleur réel à trois canaux en une représentation couleur complexe à deux canaux. Ensuite, nous utilisons une banque de filtres Gabor sur chaque canal de l'image pour extraire les informations de texture générées par les variations de couleur et d'illumination de l'image.

\section*{Abstract}
\noindent In this chapter we present the spectral decomposition of a color image by means of the Gabor filter. We use the theory about Gabor functions developed in Chapter \ref{ch:spectral_image_decomposition} to extract local texture features of a color image. The main strategy consist on transforming the input image from a three-channel real color space into a two-channel complex color representation. Then, we use a bank of Gabor filters on each channel of the image to extract the texture information generated by the variations of color and illumination in the image.

\section{Introduction}

Gabor filters have long been used for analyzing textures and extracting corresponding image features. Its adaptability and customization depending on the application and the relationship with the human visual system \citep{Daugman:JOSA:1985a}, have made this technique one of the most relevant for the analysis of textures in an image.

The use of Gabor filters for image texture analysis is highly dependent on the final application. Some of the most recognized works in the literature date back to the late 90s, where this technique was a hot research topic for image texture analysis. However, regarding the works present in the literature, we can make a clear separation of the methods taking into account the nature of the extracted features. The first group uses Gabor filters to extract a global texture descriptor (Gabor signature). Generally this strategy is suitable for applications where the images contain homogeneous textures and it is sought to make the the classification of images or an image retrieval system based on the content, as we can see in Chapter \ref{ch:similarity_measures}. The second group is characterized by using Gabor filters to obtain local texture features present in an image. Such a strategy is suitable for image segmentation tasks. In this Chapter we address in a detailed and comprehensive way the second case, delving into the spectral decomposition of color images to obtain texture features generated by the changes in illumination and/or color.

We take advantage of the Gabor function's dual-domain (spatial and frequency) representation capability to create a bank of filters $G=\{g_{f, \theta}(x, y) \}$ and obtain the spectral decomposition of an input image $I(x, y)$ through the convolution operation of each of the filters such that 
\begin{equation}\label{eq:gabor_responses}
    r_{f, \theta}(x,y) = I(x, y) \ast g_{f, \theta}(x,y)
\end{equation}
represents the filter response at different central frequencies $f$ (scales) and orientations $\theta$. Given the complex form of Gabor's filters Eq. \eqref{eq:gabor_function_2d_spacefreq_bank} defined in Chapter \ref{ch:spectral_image_decomposition}, the response of the filter $r_{f,\theta}(x, y)$ have a real and an imaginary part, here denoted as $\RE{(\cdot)}$ and $\IM{(\cdot)}$, respectively.

The linear transformation of an image using Eq. \eqref{eq:gabor_responses}, produces considerable information about the textures present in the image. The efficient manipulation of this information is the basis for the extraction of appropriate (local or global) texture features. Although the convolution of the image by a filter bank is a common denominator in techniques based on signal processing, in the literature we find various options to create more separable texture features (see Figure \ref{fig:general_pipeline_gabor_feature_extraction}). In general, these methods differ in the type of output they use to measure the textural information of the image and the in post-processing techniques to refine the Gabor responses. Among the possible Gabor filter responses to measure the texture information, some of the most used in the literature are

\begin{enumerate}
    \item Amplitude of the response (magnitude or Gabor energy) \citep{Bovik.Clark.ea:TPAMI:1990}.
        \begin{equation}\label{eq:gabor_magnitude}
            |r_{f, \theta}(x,y)| = \sqrt{\RE{(r_{f, \theta}(x, y))}^2 + \IM{(r_{f, \theta}(x, y))}^2}
        \end{equation}
    \item Phase of the response \citep{Palm.Lehmann:MGV:2002}.
    \begin{equation}\label{eq:gabor_phase}
            \arg(r_{f, \theta}(x,y)) = \arctan2{\left(\frac{\IM{(r_{f, \theta}(x, y))}}{\RE{(r_{f, \theta}(x, y))}}\right)}
        \end{equation}
    \item Real component of the response \citep{Jain.Farrokhnia:IJPR:1991}.
    \begin{equation}\label{eq:gabor_real_part}
            \RE{(r_{f, \theta}(x, y))}
        \end{equation}
    \item Square amplitude of the response (Gabor local power spectrum) \citep{Grigorescu.Petkov.ea:TIP:2002}.
    \begin{equation}\label{eq:gabor_power}
            |r_{f, \theta}(x,y)|^2 = \RE{(r_{f, \theta}(x, y))}^2 + \IM{(r_{f, \theta}(x, y))}^2
        \end{equation}
\end{enumerate}
while the most common post-processing techniques for the filter outputs consists on a non-linear transformation followed by smoothing using a rectangular or Gaussian window \citep{Randen.Husoy:TPAMI:1999}, \citep{Clausi.EdJernigan:JPR:2000}. The application of non-linearity favors the activation of the textured areas in the images, while the smoothing favors the location of the energy obtained with the filter, avoiding the loss of information from the natural contours of the image. Figure \ref{fig:general_pipeline_gabor_feature_extraction} illustrate the stages (boxes with black continuous lining) and the input/outputs (boxes with black dotted lining) of the aforementioned scheme for the extraction of Gabor-based texture features.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\textwidth]{general_pipeline_gabor_feature_extraction}
	\caption{Classic pipeline and techniques for extraction of texture features using the Gabor filters.}\label{fig:general_pipeline_gabor_feature_extraction}
\end{figure}


\subsection{Texture features for color images}
Most of the research work on texture has been done in the field of gray-scale images with homogeneous textures. In consequence, the first and simplest way to obtain texture features from color images is to transform them into a gray-scale image. This strategy favors the acceleration of feature calculation because we work with scalar values instead of vectors. However, despite the good results in images with homogeneous gray-scale textures, reducing channels for a natural color image with non-homogeneous textures does not ensure the generation of representative texture features. For example, in the case of a texture image in the RGB color space, which its gray-scale transformation represents the levels of red, green, and blue \citep{Artusi.Banterle.ea:Book:2016} as
%L = 0.2126 R + 0.7152 G + 0.00722 B
\begin{equation}\label{eq:color2gray_formula}
    L = 0.299 R + 0.587 G + 0.114 B    
\end{equation} 
in the case of isoluminant colors (colors with the same luminance value), the transformation $L$ leads to a minimization or lost, in the worst case, of textures generated by the color changes. This is because the non-homogeneous textures in a color image are not only generated by luminance variations, but also by variations in chromaticity. Moreover, the real world scenes are in color and contain non-homogeneous textures.
%\textit{Idea to develope:} Illustrate the effect of compute unichrome features in the gray-scale and the RGB space for a color image.

% for a colored real-world image containing non-homogeneous textures. 
% Although there is some texture information in the color input image,

Notwithstanding, we find a large number of methods that propose the characterization of textures in color images. Such methods generally use two strategies for the analysis of color textures \citep{Maenpaa.Pietikainen:PR:2004}, \citep{Qazi.Alata.ea:PR:2011}

\begin{itemize}
	\item process color and texture information separately
	\item process color and texture as a joint phenomenon
\end{itemize} 

The methods in the first category assume that the spatial variations that form textures and color distributions of the image are independent cues (see for example \citep{Permuter.Francos.ea:PR:2006}). We differ from this point of view and we consider that color and texture information in a image are a joint phenomenon based on the idea that textural segmentation occurs on the basis of the distribution of simple properties of texture elements, for example, the brightness, color, size, and the slopes of contours and other elemental descriptors of a texture \citep{Werner.Chalupa:Book:2004}.
 
In this regard, there are various techniques to joint color and texture information for the characterization of natural color textures. A popular option is to get unichromatic texture features from
of each color channel of the image using, for example, Gabor filters. Taking the RGB color space as a reference, the responses of the filters represent the texture features of each primary color red, green and blue independently, i.e., in principle this strategy does not involve the correlation between RGB band colors. This might be corrected using the opponent color model based on the human color vision theory \citep{Jain.Healey:TIP:1998}. In such case, 
each unichromatic feature vector (RGB-feature) is multiplied and normalized by the feature vector of its opponent color to include the correlation between color channels \citep{Palm.Keysers.ea:JCIS:2000}. This method manages to gather the information of color and texture under a frame of human color perception, however, the normalization and multiplication of the unichromatic texture feature vectors implies extra steps of post-processing in the extraction pipeline of features. 

One way to avoid the post-processing stage after the image Gabor decomposition is to first transform the color image in a color space that handles the coupling between the color channels rather than separating them as individual components of the color space. The quaternion framework \citep{Sangwine.Ell:VISP:2000} provides this possibility of coupled color representation. It encodes the color value of each pixel in a pure quaternion, where the real component is set to zero and the three imaginary components represent the color band such as $I(x, y) = R (x, y) \hat{i} + G (x, y) \hat{j} + B (x, y) \hat{k} $. This 3-component vector representation yields a system which has well-defined mathematical operations, such as Quaternion Fourier Transform, that makes possible the Gabor image decomposition by means of the Quaternion Gabor Filters (QBF) \citep{Subakan.Vemuri:EMMCVPR:2009}. However, when using quaternion values, the non-existing commutativity has to be taken into account, in addition, the QGF does not support any physic interpretation of what is measured. 

Another alternative to this problem is to represent the image in one of the two-channel color spaces, previously defined in Chapter 2, where one channel contains the luminance information and the other the chrominance information of the image. Such a representation can be obtained from non-linear color spaces like LAB or LUV, as well as from HSV or HSL perceptual color spaces. The representation in the form of luminance-chrominance has the characteristic of concentrating the color information in a complex channel, which is compatible with the multispectral Gabor decomposition. In both cases, the choice of a pertinent color space for the characterization of the texture is necessary \citep{Qazi.Alata.ea:PR:2011}.

The methodology that we present in this chapter for the segmentation of natural color images mainly follows the stages shown in the diagram of figure \ref{fig:general_pipeline_gabor_feature_extraction}. The modifications proposed to this scheme are: the transformation of the input image from the RGB color space to one of the luminance-chrominance spaces (or complex two-channel color spaces) described in Chapter \ref{ch:color_texure_representations}. Then, the replacement of the non-linear transformation by a morphological opening to highlight the amplitude of the filter responses and finally, we apply an adaptive Gaussian smoothing. Under this configuration, we obtain a spectral decomposition of the image that takes into account the textures generated by changes in lighting but also by those generated by color changes. 

\section{Spectral decomposition of color images}
The figure \ref{fig:proposed_pipeline_gabor_feature_extraction} shows a general diagram with the stages that we follow for the extraction of local features.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\textwidth]{gabor_color_feature_extraction_diagram}
	\caption{Proposed methodology for the computation of Gabor features in color images.}\label{fig:proposed_pipeline_gabor_feature_extraction}
\end{figure}


\subsection{Synthetic image description}

The representation in two channels, one real and the other complex, of a color image allows us to separate the intervention of luminance and colors in the generation of textures in the image. To help visualize such a joint phenomenon, we create a synthetic that try to reflect the complextiy of natural color images. The proposed image contains seven different regions with spatial variations generated by the combination of different colors. The input image is generated by the sign of a 2-d sinusoidal signal multiplied by the color values of each region in the RGB color space such that  
\begin{gather}
	I(x, y) = sgn( \sin 2 \pi (f_x x_r + f_y y_r)) \cdot [R, G, B]\label{eq:2D_squared_signal}\\
	x_r = x \cos\theta + y \sin\theta \nonumber \\
    y_r = -x \sin\theta + y \cos\theta \nonumber  
\end{gather}

We modulate the image texture by varying the frequencies $f_{x}, f_{y}$ and the orientation angle $\theta$ of the coordinate plane $(x, y)$, where $\theta=0^\circ$ means vertical variations and $\theta=90^\circ$ horizontal variations. The image we propose is $320\times1400$ pixels where every 200 pixels (on the $x$-axis) there is a change in color and/or texture. Specifically, the spatial variations are defined by the following expressions. 
\begin{gather}
	f_{x} = 
	\begin{cases} 
      0    & 0\leq x\leq 200  \\
      1/64 & 201\leq x\leq 400  \\
      1/32 & 401\leq x\leq 600  \\
      1/16 & 601\leq x\leq 800  \\
      1/8  & 801\leq x\leq 1000  \\
      1/4  & 1001\leq x\leq 1200 \\   
      1/4  & 1201\leq x\leq 1400 \\ 
   	 \end{cases} \nonumber ; \quad
   	 f_{y} = \begin{cases} 
      0    & 0\leq x\leq 200  \\
      0    & 201\leq x\leq 400  \\
      0    & 401\leq x\leq 600  \\
      0    & 601\leq x\leq 800  \\
      0    & 801\leq x\leq 1000  \\
      0    & 1001\leq x\leq 1200 \\  
      1/16 & 1201\leq x\leq 1400 \\ 
   	 \end{cases} \nonumber  
\end{gather}


For comprehension purposes, we use colors that are easily identified in the RGB space (primary colors) or in the HSV space (perceptual colors) to generate the textures in the image. The resulting synthetic image is depicted by the figure \ref{fig:synthetic_color_texture_image}.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth]{synthetic_image_color_texture}
\caption{Synthetic color textured image.}\label{fig:synthetic_color_texture_image}
\end{figure}

The 2-d sinusoidal modulations generates textures in the image at a different and well known frequencies. These modulations change the colors of the regions generating a texture of oriented lines. The regions of the synthetic image have the following color and texture characteristics.

\paragraph{Region 1. Textureless zone:}
This region does not contain spatial variations, i.e., it has only a solid color. The color of the region is yellow.

\paragraph{Region 2. Lowest frequency textured zone with colors on the imaginary plane:}
This region is described by the vertical texture generated by variations between purple and green lime. Such colors are found in the imaginary axis of the chrominance plane. The colors in this region change every 64 pixels.

\paragraph{Region 3. Textured zone with colors on the real plane:}
This region contains an vertical texture generated by the variations between red and cyan. Such colors are found in the real axis of the chrominance plane. The colors in this region change every 32 pixels.

\paragraph{Region 4. Textured zone with two primary colors:}
The horizontal texture of this region is generated by the variations between red and blue. The colors in this region change every 16 pixels. 

\paragraph{Region 5. Textured zone with two primary colors:}
The horizontal texture of this region is generated by the variations between blue and green. The colors in this region change every 8 pixels. 

\paragraph{Region 6. Textured zone with two primary colors:}
The horizontal texture of this region is generated by the variations between green and red. The colors change every 4 pixels.

\paragraph{Region 7. Colorless mixed textures zone:}
This region contains two textures, both of them formed by the variations between black and white, i.e., there is no color information. Moreover, the textures change in frequency and orientation; the pixes of the horizontal texture change of color every 4 pixels (highest frequency), while the pixel values of the vertical texture changes every 16 pixels (same frequency as region 4).

The colors and frequency of each zone are summarized in Table \ref{tab:synthetic_image_components}. In it, we expose the $RGB$ and $HSV$ values of the texture-forming colors as well as the frequency and orientation of each section.


\begin{table}[h!]
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|ccccccc}
                    & \multicolumn{7}{c}{\textbf{Region}}                                                                                                                                                                          \\ \hline
\textbf{}           & 1                  & 2                   & 3                   & 4                   & 5                   & 6                   & 7                                                              \\ \hline
\textbf{Color 1}    &                    &                     &                     &                     &                     &                     &                                                                \\
\textit{Name}       & Yellow             & Purple              & Red                 & Red                 & Blue                & Green               & Black                                                          \\
\textit{RGB values} & {[}255, 255, 0{]}  & {[}128, 0, 255{]}   & {[}255, 0, 0{]}     & {[}255, 0, 0{]}     & {[}0, 0, 255{]}     & {[}0, 255, 0{]}     & {[}0, 0, 0{]}                                                  \\
\textit{HSV values} & {[}60, 100, 100{]} & {[}270, 100, 100{]} & {[}0, 100, 100{]}   & {[}0, 100, 100{]}   & {[}240, 100, 100{]} & {[}120, 100, 100{]} & {[}0, 0, 0{]}                                                  \\ \hline
\textbf{Color 2}    &                    &                     &                     &                     &                     &                     &                                                                \\
\textit{Name}       & -                  & Green lime          & Cyan                & Blue                & Green               & Red                 & White                                                          \\
\textit{RGB values} & -                  & {[}128, 255, 0{]}   & {[}0, 255, 255{]}   & {[}0, 0, 255{]}     & {[}0, 255, 0{]}     & {[}255, 0, 0{]}     & {[}255, 255, 255{]}                                            \\
\textit{HSV values} & -                  & {[}90, 100, 100{]}  & {[}180, 100, 100{]} & {[}240, 100, 100{]} & {[}120, 100, 100{]} & {[}0, 100, 100{]}   & {[}0, 0, 100{]}                                                \\ \hline
\textbf{Texture}    &                    &                     &                     &                     &                     &                     &                                                                \\
\textit{Freq.}      & -                  & $1/64$              & $1/32$              & $1/16$              & $1/8$               & $1/4$               & \begin{tabular}[c]{@{}c@{}}$1/4$\\ $1/16$\end{tabular}         \\
\textit{Angle}      & -                  & $90^\circ$          & $90^\circ$          & $90^\circ$          & $90^\circ$          & $90^\circ$          & \begin{tabular}[c]{@{}c@{}}$0^\circ$\\ $90^\circ$\end{tabular}
\end{tabular}}
\caption{Specifications of the color and texture settings for each of the regions within the synthetic image.}\label{tab:synthetic_image_components}
\end{table}



\begin{figure}[h!]
	\centering
    \includegraphics{color_complex_plane}
\caption{Synthetic image chrominance distribution represented in the color complex plane.}\label{fig:color_complex_plane}
\end{figure}


%\begin{table}[h!]
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{c|c|c|c|c|c|c|c|c|}
%\cline{2-9}
%\textbf{}                                & \multicolumn{6}{c|}{\textbf{Colors}}                                                                                                                                        & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Texture}}} \\ \cline{2-7}
%                                         & \multicolumn{3}{c|}{\textbf{Color 1}}                                            & \multicolumn{3}{c|}{\textbf{Color 2}}                                                    & \multicolumn{2}{c|}{}                                  \\ \hline
%\multicolumn{1}{|c|}{\textbf{Zone}}      & \textbf{Name}          & \textbf{$RGB$ values}      & \textbf{$HSV$ values}      & \textbf{Name}          & \textbf{$RGB$ values}            & \textbf{$HSV$ values}        & \textbf{Freq.}             & \textbf{Angle}            \\ \hline
%\multicolumn{1}{|c|}{1}                  & Yellow                 & $[255,255,0]$              & $[60,100,100]$             & n/a                    & n/a                              & n/a                          & n/a                        & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{2}                  & Purple                 & $[128, 0, 255]$            & $[270,100,100]$            & Green lime             & $[128, 255, 0]$                  & $[90,100,100]$               & $\frac{1}{64}$             & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{3}                  & Red                    & $[255,0,0]$                & $[0,100,100]$              & Cyan                   & $[0,255,255]$                    & $[180,100,100]$              & $\frac{1}{32}$             & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{4}                  & Red                    & $[255,0,0]$                & $[0,100,100]$              & Blue                   & $[0,0,255]$                      & $[240,100,100]$              & $\frac{1}{16}$             & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{5}                  & Blue                   & $[0,0,255]$                & $[240,100,100]$            & Green                  & $[0,255,0]$                      & $[120,100,100]$              & $\frac{1}{8}$              & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{6}                  & Green                  & $[0,255,0]$                & $[120,100,100]$            & Red                    & $[255,0,0]$                      & $[0,100,100]$                & $\frac{1}{4}$              & $90^\circ$                \\ \hline
%\multicolumn{1}{|c|}{\multirow{2}{*}{7}} & \multirow{2}{*}{Black} & \multirow{2}{*}{$[0,0,0]$} & \multirow{2}{*}{$[0,0,0]$} & \multirow{2}{*}{White} & \multirow{2}{*}{$[255,255,255]$} & \multirow{2}{*}{$[0,0,100]$} & $\frac{1}{4}$              & $90^\circ$                \\ \cline{8-9} 
%\multicolumn{1}{|c|}{}                   &                        &                            &                            &                        &                                  &                              & $\frac{1}{32}$             & $0^\circ$                 \\ \hline
%\end{tabular}}
%\caption{Specifications of color and texture of the areas of the synthetic study image.}\label{tab:synthetic_image_components}
%\end{table}

The choice of texture forming colors comes from the interest in visualizing the color spectrum of the image in a more representative way. Throughout this work, we will use the representation of color in two-complex channels from the HSV color space given by Eq. \eqref{eq:chrominance_hsv}.

Considering that the colors of the input image are initially expressed in spectral light primaries RGB, if we look at the colors in the HSV space on the complex chrominance plane (see Fig. \ref{fig:color_complex_plane}), a pure value of hue ($H$) equivalent to a full saturation corresponds to the ratio of the dominant wavelength to other wavelengths in color. The saturation ($S$) or chroma defines the brilliance and intensity (purity) of a color; it refers to the dominance of hue in the color. Finally, the value ($V$) refers to the lightness or darkness of a color; it indicates the quantity of light reflected.


Since for the representation in two complex channels the value $V$ of each pixel is not necessary, we can plot the pixel values of hue $H$ (in degrees) and saturation $S$ (normalized between $0$ and $255$) in the complex 2-d plane shown in the Figure \ref{fig:color_complex_plane}. This representation completes the description of our synthetic test image showing the variation between colors that generate textures. We can see in Figure \ref{fig:color_complex_plane} the transition between the $RGB$ primary colors at $0^\circ$, $120^\circ$ and $240^\circ$ respectively; the transition between purple and lime green on the imaginary axis with a hue of $90^\circ$ and $270^\circ$ respectively; the transition between red at $0^\circ$ and cyan at $180^\circ$ passing through the real axis of the plane and finally the yellow color with a hue value of $60^\circ$ in the chroma circle.

Now that the colors are represented in the two complex channels, it only remains to represent the spatial variations produced by the intensity changes. Generally when the complex representation of two channels is used, the lighting is not taken into account or, the $L$ channels of the LAB space or $V$ of the HSV space take on this role. In our case, we use the transformation of the image in $RGB$ to the gray-scale following the Eq. \eqref{eq:color2gray_formula}. Then, if we plot these three channels separately ($L(x,y)$, $\RE(C(x,y))$, $\IM(C(x,y))$), Figure \ref{fig:synthetic_image_three_channel_decomposition}, and consider a horizontal line through the synthetic image, Figure \ref{fig:horizontal_line_three_channel_decomposition}, we can observe the variations generated by changes in color or changes in intensity. For example, taking the area without texture (region 1), the horizontal line between pixels 0 and 200 remains constant in all three channels due to the absence of texture. Observing region 2, which corresponds to the low frequency texture formed by the colors at 90 and 180 in the chroma circle, we can see that the variations are only present in the imaginary channel of chrominance $\IM(C(x,y))$; while for the last region (colorless mixed textures zone), we can see that the variations are only present in the channel that describes the luminance $L(x,y)$.

\begin{figure}
\centering
    \subcaptionbox{\label{fig:synthetic_image_three_channel_decomposition}}{\includegraphics[width=\textwidth]{synthetic_image_three_channel_decomposition}}
    \subcaptionbox{\label{fig:horizontal_line_three_channel_decomposition}}{\includegraphics[width=\textwidth]{horizontal_line_three_channel_decomposition}}    
\caption{Illustration of the proposed synthetic image: (a) Luminance and chrominance decomposition; (b) Horizontal line trough the three channels.}\label{fig:three_channel_decomposition}
\end{figure}

\subsection{Image Gabor energy}
Nosotros utilizamos la amplitud de la respuesta de los filtros de Gabor Eq. \eqref{eq:gabor_magnitude} para medir la informacion de textura de las imagenes

\begin{equation}\label{eq:gabor_energy}
	e_{f, \theta}(x,y) = |r_{f, \theta}(x,y)|
\end{equation}


\begin{equation}\label{eq:gabor_energy}
	\widehat{e}_{f, \theta}(x,y) = \gamma_B(e_{f, \theta}(x,y)) = \delta_B[\varepsilon_B(e_{f, \theta}(x,y)]
\end{equation}


\begin{equation}\label{eq:gabor_energy}
	\widetilde{e}_{f, \theta}(x,y) = W(x, y, \sigma_{f, \theta})\ast \widehat{e}_{f, \theta}(x,y)
\end{equation}

\begin{eqnarray}\label{eq:LoG}
l_\sigma =  \nabla^{2} 
\end{eqnarray}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{GaborFilterbank_5f_4a}
    \caption{Gabor filter bank with filters with five frequencies and four orientations for texture image model.}\label{fig:gabrfilter_5f_4a}    
\end{figure}



\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_lum_synthetic_00}
        \caption{Luminance channel responses}
    \end{subfigure} \\    
    \begin{subfigure}[b]{\textwidth}
    	\includegraphics[width=\textwidth]{gabor_resp_cr_synthetic_00}
        \caption{Real part of chrominance channel responses}
    \end{subfigure} \\    	
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_ci_synthetic_00}
        \caption{Imaginary part of chrominance channel responses}
    \end{subfigure} 
    	    
    \caption{Spectral decomposition of synthetics texture/color image.}\label{fig:synthetic_img_gresponses}    
\end{figure}

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_lum_synthetic_00_opn}
        \caption{Luminance channel responses}
    \end{subfigure} \\    
    \begin{subfigure}[b]{\textwidth}
    	\includegraphics[width=\textwidth]{gabor_resp_cr_synthetic_00_opn}
        \caption{Real part of chrominance channel responses}
    \end{subfigure} \\    	
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_ci_synthetic_00_opn}
        \caption{Imaginary part of chrominance channel responses}
    \end{subfigure} 
    	    
    \caption{Spectral decomposition of synthetics texture/color image.}\label{fig:synthetic_img_gresponses}    
\end{figure}

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_lum_synthetic_00_opn_smth}
        \caption{Luminance channel responses}
    \end{subfigure} \\    
    \begin{subfigure}[b]{\textwidth}
    	\includegraphics[width=\textwidth]{gabor_resp_cr_synthetic_00_opn_smth}
        \caption{Real part of chrominance channel responses}
    \end{subfigure} \\    	
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_ci_synthetic_00_opn_smth}
        \caption{Imaginary part of chrominance channel responses}
    \end{subfigure} 
    	    
    \caption{Spectral decomposition of synthetics texture/color image.}\label{fig:synthetic_img_gresponses}    
\end{figure}



\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_lum_synthetic}
        \caption{Luminance channel responses}
    \end{subfigure} \\    
    \begin{subfigure}[b]{\textwidth}
    	\includegraphics[width=\textwidth]{gabor_resp_cr_synthetic}
        \caption{Real part of chrominance channel responses}
    \end{subfigure} \\    	
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{gabor_resp_ci_synthetic}
        \caption{Imaginary part of chrominance channel responses}
    \end{subfigure} 
    	    
    \caption{Spectral decomposition of synthetics texture/color image.}\label{fig:synthetic_img_gresponses}    
\end{figure}



\section{Gabor feature space validation}
The feature space calculated from the spectral decomposition of the image captures the color and texture information generated by changes in color and lighting in the image. To visually validate the quality of the feature space, we implement three clustering methods. In addition, we also propose a set of high-level features based on Gabor energy recovered from the real and complex channels of the image.

\subsection{Clustering methods as a technique for color image segmentation}

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{kmeans_7segms_synthetic}
        \caption{7 clusters segmentation}
    \end{subfigure} \\    
    \begin{subfigure}[b]{\textwidth}
    	\includegraphics[width=\textwidth]{kmeans_2segms_synthetic}
        \caption{2 clusters segmentation}
    \end{subfigure} 
        	    
    \caption{Synthetic image k-means segmentation results.}\label{fig:kmeans_segms_synthetic_img}    
\end{figure}


\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{0.19\textwidth}
        \includegraphics[width=\textwidth]{mosaic_dtd1}
    \end{subfigure} 
    \begin{subfigure}[b]{0.19\textwidth}
    	\includegraphics[width=\textwidth]{mosaic_dtd2}
    \end{subfigure}     
    \begin{subfigure}[b]{0.19\textwidth}
        \includegraphics[width=\textwidth]{mosaic_dtd3}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
    	\includegraphics[width=\textwidth]{mosaic_dtd4}
    \end{subfigure}    
    \begin{subfigure}[b]{0.19\textwidth}
        \includegraphics[width=\textwidth]{mosaic_dtd5}
    \end{subfigure} \\ [2ex]
    
    \begin{subfigure}[b]{0.19\textwidth}
    	\includegraphics[width=\textwidth]{mosaic_dtd1_kmeans_segms}
        \caption{}
    \end{subfigure}     
    \begin{subfigure}[b]{0.19\textwidth}
        \includegraphics[width=\textwidth]{mosaic_dtd2_kmeans_segms}
        \caption{}
    \end{subfigure} 
    \begin{subfigure}[b]{0.19\textwidth}
    	\includegraphics[width=\textwidth]{mosaic_dtd3_kmeans_segms}
        \caption{}
    \end{subfigure}     
    \begin{subfigure}[b]{0.19\textwidth}
        \includegraphics[width=\textwidth]{mosaic_dtd4_kmeans_segms}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
    	\includegraphics[width=\textwidth]{mosaic_dtd5_kmeans_segms}
        \caption{}
    \end{subfigure} 
        	    
    \caption{Synthetic image k-means segmentation results.}\label{fig:kmeans_segms_dtd_mosaics}    
\end{figure}

\subsection{Berkely Segmentation Image Data Set}
The Berkely Database for Segmentation (BSDS) is one of the gold standards for segmentation results \citep{Martin.Fowlkes.ea:ICCV:2001}. The database is made up of images from the Corel database selected under a simple criterion: choose images of complex and natural scenes that contain at least one distinguishable object. Under this criteria, selected images contain multiple cues for human segmentation. For example, low-level cues such as coherence of brightness, texture and color or contour continuity; mid-level cues such as symmetry, convexity and area of the regions; as well as high-level cues based on the semantics of the image objects.

There are two versions of this database. The first one contains 300 (BSDS300) images while the second contains (BSDS500). Each image in the database contains between 5 and 11 human-made segmentations. The instruction given to the observers to break the scene in a natural way is simple: \textit{Divide each image into pieces, where each piece represents a distinguished thing in the image. It is important that all of the pieces have approximately equal importance. The number of things in each image is up to you. Something between 2 and 30 should be reasonable for any of our images }\citep{Martin.Fowlkes.ea:ICCV:2001}. Following these instructions, most segmentations meet the criterion of the number of segments, however, we can also find exceptions with more than 50 segmented things.

Finally, both databases (BSDS300 and BSDS500) contain segmentations of the images in gray level and color. Since in this chapter we analyze the color textures, we mainly use the BSDS500 color images with their respective segmentations for the evaluation of our segmentation results. Figure 3 shows some examples of images from the BSDS500 and the segmentations produced by different humans.

\subsection{Evaluation Methodology}
We use the human-generated segmentations of the BSDS500 as ground truth (GT) applying the precision-recall framework of \cite{Martin.Fowlkes.ea:PAMI:2004}. The precision is the fraction of detections that are true positives rather than false positives while the recall is the fraction of true positives that are detected rather than missed. This evaluation framework is generally applied to evaluate contour detection algorithms. Therefore, applied in the image segmentation task, it involves evaluating the boundaries of the segmentation resulting regions, considering the detected boundaries pixels as a two-classes classification problem (contour and non-contour pixels). Under this configuration, precision is translated as the number of pixels correctly labeled as belonging to the contour class (true positives) divided by the total number of pixels labeled as contours (the sum of true positives and false positives). The recall in this context is defined as the number of true positives divided by the sum of true positives and the pixels which were not labeled as contours, but should have been (false negatives). The following mathematical expressions define the precision of the recall. 

\begin{equation}\label{eq:precision_score}
    \text{precision} = \frac{tp}{tp+fp}
\end{equation}

\begin{equation}\label{eq:recall_score}
    \text{recall} = \frac{tp}{tp+fn}
\end{equation}

A simple metric that captures the trade-off between precision and recall is the f-measure, which is defined as the harmonic mean between pressure and recall.

\begin{equation}\label{eq:f_score}
    \text{F-measure} = \frac{2 \times \text{precision}\times\text{recall}}{\text{precision} + \text{recall}}
\end{equation}


\subsubsection{k-means clustering}
\subsubsection{Gaussian mixture clustering}
\subsubsection{Birch clustering}


%\begin{figure}[!ht]
%    
%    \begin{subfigure}[b]{0.24\textwidth}
%    	\centering
%    	\includegraphics[height=2.5cm]{a01_100007_Birch_min_segm}
%        \caption{}
%        \label{fig:}
%    \end{subfigure}
%    %~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.24\textwidth}
%    	\centering
%        \includegraphics[height=2.5cm]{a02_160067_Birch_min_segm}
%        \caption{}
%        \label{fig:}
%    \end{subfigure} 
%    %~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
%      %(or a blank line to force the subfigure onto a new line)    
%    \begin{subfigure}[b]{0.24\textwidth}
%    	\centering
%        \includegraphics[height=2.5cm]{a03_2018_Birch_min_segm}
%        \caption{}
%        \label{fig:}
%    \end{subfigure}
%    %~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.24\textwidth}
%    	\centering
%        \includegraphics[height=2.5cm]{a04_175083_Birch_min_segm}
%        \caption{}
%        \label{fig:}
%    \end{subfigure}
%                  
%    \caption{Some examples of color images: One synthetic image {\small \textsf{\textbf{(a)}}} and three natural images {\small \textsf{\textbf{(b) (c) (d)}}}.}\label{fig:clustering_results}    
%\end{figure}


\begin{figure}[!ht]
         
    \begin{subfigure}[t]{\dimexpr0.23\textwidth+20pt\relax}
    	\centering
    	\makebox[20pt]{\raisebox{30pt}{ \rotatebox[origin=c]{90} {\small \textsf{\textbf{Input image}}} }}%
    	\includegraphics[width=\dimexpr\linewidth-20pt\relax]{a01_100007_Birch_min_segm} 
    \end{subfigure}      
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a02_160067_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a03_2018_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a04_175083_Birch_min_segm}
    \end{subfigure} \vspace{5pt}   
    
    
    \begin{subfigure}[t]{\dimexpr0.23\textwidth+20pt\relax}
    	\centering
    	\makebox[20pt]{\raisebox{30pt}{ \rotatebox[origin=c]{90} {\small \textsf{\textbf{Kmeans}}} }}%
    	\includegraphics[width=\dimexpr\linewidth-20pt\relax]{a01_100007_Birch_min_segm} 
    \end{subfigure}      
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a02_160067_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a03_2018_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a04_175083_Birch_min_segm}
    \end{subfigure} \vspace{5pt}
    
    
    \begin{subfigure}[t]{\dimexpr0.23\textwidth+20pt\relax}
    	\centering
    	\makebox[20pt]{\raisebox{30pt}{ \rotatebox[origin=c]{90} {\small \textsf{\textbf{Fast Kmeans}}} }}%
    	\includegraphics[width=\dimexpr\linewidth-20pt\relax]{a01_100007_Birch_min_segm} 
    \end{subfigure}      
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a02_160067_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a03_2018_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a04_175083_Birch_min_segm}
    \end{subfigure} \vspace{5pt}
    
    
    \begin{subfigure}[t]{\dimexpr0.23\textwidth+20pt\relax}
    	\centering
    	\makebox[20pt]{\raisebox{30pt}{ \rotatebox[origin=c]{90} {\small \textsf{\textbf{Gaussian mixture}}} }}%
    	\includegraphics[width=\dimexpr\linewidth-20pt\relax]{a01_100007_Birch_min_segm} 
    \end{subfigure}      
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a02_160067_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a03_2018_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a04_175083_Birch_min_segm}
    \end{subfigure} \vspace{5pt}
    
    
    \begin{subfigure}[t]{\dimexpr0.23\textwidth+20pt\relax}
    	\centering
    	\makebox[20pt]{\raisebox{30pt}{ \rotatebox[origin=c]{90} {\small \textsf{\textbf{Birch}}} }}%
    	\includegraphics[width=\dimexpr\linewidth-20pt\relax]{a01_100007_Birch_min_segm} 
    \end{subfigure}      
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a02_160067_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a03_2018_Birch_min_segm}
    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.23\textwidth}
    	\centering
        \includegraphics[height=67.68857pt]{a04_175083_Birch_min_segm}
    \end{subfigure} 
    
	\caption{}\label{fig:}    
\end{figure}

\section{Conclusion}
